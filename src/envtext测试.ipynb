{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:在全球气候大会上，[MASK][MASK][MASK][MASK]是各国政府都关心的话题 \n",
      "  predict: ['气', '体', '减', '少'] ; probability: 0.5166 \n",
      "  predict: ['气', '体', '减', '排'] ; probability: 0.5166 \n",
      "  predict: ['气', '体', '减', '碳'] ; probability: 0.5166 \n",
      "  predict: ['气', '体', '减', '缓'] ; probability: 0.5166 \n",
      "  predict: ['气', '体', '减', '量'] ; probability: 0.5166 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from envtext import  BertMLM,Config\n",
    "model = BertMLM(Config.bert.bert_mlm)\n",
    "model(\"在全球气候大会上，[MASK][MASK][MASK][MASK]是各国政府都关心的话题\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../../2022Spring/EnvText/models/envbert/ were not used when initializing BertREG: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertREG from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertREG from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertREG were not initialized from the model checkpoint at ../../../2022Spring/EnvText/models/envbert/ and are newly initialized: ['regressor.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'regressor.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 512, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'architectures': ['BertForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': 0, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '../../../2022Spring/EnvText/models/envbert/', 'transformers_version': '4.22.1', 'directionality': 'bidi', 'model_type': 'bert', 'output_past': True, 'pooler_fc_size': 768, 'pooler_num_attention_heads': 12, 'pooler_num_fc_layers': 3, 'pooler_size_per_head': 128, 'pooler_type': 'first_token_transform', 'vocab_size': 21128, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 512, 'type_vocab_size': 2, 'initializer_range': 0.02, 'layer_norm_eps': 1e-12, 'position_embedding_type': 'absolute', 'use_cache': True, 'classifier_dropout': None, 'package': 'envtext', 'liscence': 'Apache Lisence', 'contact': 'bi.huaibin@foxmail.com', 'mirror': 'https://mirror.nju.edu.cn/hugging-face-models', 'model_name': 'bert_sa', 'range': [[0, 1]], 'visualizer': 'sa', 'key_metric': 'loss', 'path': '../../../2022Spring/EnvText/EnvCLUE数据集/SA_Intensity.json', 'task': 'REG', 'format': None, 'sampler': 1, 'split': 0.8, 'label_as_key': False, 'label_inline': False, 'ner_encoding': 'BIO', 'sep': ' ', 'dataset': 'dataset', 'train': 'train', 'valid': 'valid', 'test': 'test', 'text': 'text', 'label': 'label', 'entity_label': 'label', 'loc': 'loc'}\n",
      "******* 读取数据集成功 *******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../../2022Spring/EnvText/models/envbert/ were not used when initializing BertREG: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertREG from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertREG from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertREG were not initialized from the model checkpoint at ../../../2022Spring/EnvText/models/envbert/ and are newly initialized: ['regressor.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'regressor.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from envtext import BertSA\n",
    "model = BertSA(\"../../../2022Spring/EnvText/models/envbert/\")\n",
    "model.load_dataset(\"../../../2022Spring/EnvText/EnvCLUE数据集/SA_Intensity.json\",task =\"sa\",split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function BertBase._tokenizer_for_training at 0x0000020F71669EE0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: \n",
      " Dataset({\n",
      "    features: ['text', 'raw_label', 'label'],\n",
      "    num_rows: 2210\n",
      "})\n",
      "valid dataset: \n",
      " Dataset({\n",
      "    features: ['text', 'raw_label', 'label'],\n",
      "    num_rows: 945\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8e1379de4c4518bbb7a1a9ca8e4abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2210 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6578180707ff4e08978d1ab1731a7975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/945 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertREG.forward` and have been ignored: raw_label, text. If raw_label, text are not expected by `BertREG.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2210\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2212\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='554' max='2212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 554/2212 03:10 < 09:31, 2.90 it/s, Epoch 1/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='236' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [236/237 00:30 < 00:00, 7.64 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertREG.forward` and have been ignored: raw_label, text. If raw_label, text are not expected by `BertREG.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 945\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 945\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to checkpoint\\checkpoint-553\n",
      "Configuration saved in checkpoint\\checkpoint-553\\config.json\n",
      "Model weights saved in checkpoint\\checkpoint-553\\pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint\\checkpoint-553\\tokenizer_config.json\n",
      "Special tokens file saved in checkpoint\\checkpoint-553\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertREG.forward` and have been ignored: raw_label, text. If raw_label, text are not expected by `BertREG.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 945\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to checkpoint\\checkpoint-1106\n",
      "Configuration saved in checkpoint\\checkpoint-1106\\config.json\n",
      "Model weights saved in checkpoint\\checkpoint-1106\\pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint\\checkpoint-1106\\tokenizer_config.json\n",
      "Special tokens file saved in checkpoint\\checkpoint-1106\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertREG.forward` and have been ignored: raw_label, text. If raw_label, text are not expected by `BertREG.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 945\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to checkpoint\\checkpoint-1659\n",
      "Configuration saved in checkpoint\\checkpoint-1659\\config.json\n",
      "Model weights saved in checkpoint\\checkpoint-1659\\pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint\\checkpoint-1659\\tokenizer_config.json\n",
      "Special tokens file saved in checkpoint\\checkpoint-1659\\special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint\\checkpoint-553] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertREG.forward` and have been ignored: raw_label, text. If raw_label, text are not expected by `BertREG.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 945\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to checkpoint\\checkpoint-2212\n",
      "Configuration saved in checkpoint\\checkpoint-2212\\config.json\n",
      "Model weights saved in checkpoint\\checkpoint-2212\\pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint\\checkpoint-2212\\tokenizer_config.json\n",
      "Special tokens file saved in checkpoint\\checkpoint-2212\\special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint\\checkpoint-1659] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoint\\checkpoint-1106 (score: 0.06991828978061676).\n"
     ]
    }
   ],
   "source": [
    "model.train(epoch=4,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"line-height:2.5;\"/> \n",
       "        <progress value='0.6578254103660583' max='1'></progress>\n",
       "        中国到现在都没有达到3000年的平均气温，现在就把近期时间气温上升跟工业革命联系起来是不是为时尚早？即便没有工业革命1743年中国北方的罕见高温，1743年7月20至25日，华北地区下午的气温均高于40℃。其中7月25日最热，气温高达44.4℃。这样的极端高温纪录，迄今从未被超越。民国三十一年(公元1942年)和公元1999年夏季，华北地区先后出现了两次极端高温纪录，分别为42.6℃、42.2℃，均低于乾隆八年的温度。又要算到什么头上呢？！！！"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([0.6578254], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from envtext import  BertSA\n",
    "model = BertSA(\"bert_sa\")\n",
    "model(\"中国到现在都没有达到3000年的平均气温，现在就把近期时间气温上升跟工业革命联系起来是不是为时尚早？即便没有工业革命1743年中国北方的罕见高温，1743年7月20至25日，华北地区下午的气温均高于40℃。其中7月25日最热，气温高达44.4℃。这样的极端高温纪录，迄今从未被超越。民国三十一年(公元1942年)和公元1999年夏季，华北地区先后出现了两次极端高温纪录，分别为42.6℃、42.2℃，均低于乾隆八年的温度。又要算到什么头上呢？！！！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envtext import SpanVisualizer\n",
    "viz = SpanVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"spans\" style=\"line-height: 2.5; direction: left\">\n",
       "    <span style=\"font-weight: bold; display: inline-block; position: relative; height: 77px;\">\n",
       "        北京市\n",
       "        \n",
       "    <span style=\"background: #17BECF; top: 40px; height: 4px; left: -1px; width: calc(100% + 20px); position: absolute;\">\n",
       "    </span>\n",
       "    \n",
       "    <span style=\"background: #DBDB8D; top: 57px; height: 4px; left: -1px; width: calc(100% + 20px); position: absolute;\">\n",
       "    </span>\n",
       "    \n",
       "        \n",
       "    <span style=\"background: #17BECF; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 20px); position: absolute;\">\n",
       "        <span style=\"background: #17BECF; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "            政府部门\n",
       "        </span>\n",
       "    </span>\n",
       "    \n",
       "    <span style=\"background: #DBDB8D; top: 57px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 20px); position: absolute;\">\n",
       "        <span style=\"background: #DBDB8D; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "            地点\n",
       "        </span>\n",
       "    </span>\n",
       "    \n",
       "    </span>\n",
       "    \n",
       "    <span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "        生态环境\n",
       "        \n",
       "    <span style=\"background: #17BECF; top: 40px; height: 4px; left: -1px; width: calc(100% + 20px); position: absolute;\">\n",
       "    </span>\n",
       "    \n",
       "        \n",
       "    </span>\n",
       "    \n",
       "    <span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "        局\n",
       "        \n",
       "    <span style=\"background: #17BECF; top: 40px; height: 4px; left: -1px; width: calc(100% + 20px); position: absolute;\">\n",
       "    </span>\n",
       "    \n",
       "        \n",
       "    </span>\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from envtext import  BertDP\n",
    "model = BertDP(\"bert_span_token\")\n",
    "model(\"北京市生态环境局\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envtext import DependencyVisualizer\n",
    "viz = DependencyVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    \"北京市\",\n",
    "    \"生态环境\",\n",
    "    \"局\"\n",
    "]\n",
    "\n",
    "spans = [\n",
    "{\n",
    "    \"start_token\":0,\n",
    "    \"label\" : \"地点\",\n",
    "    \"end_token\":1\n",
    "},\n",
    "{\n",
    "    \"start_token\":0,\n",
    "    \"label\" : \"政府部门\",\n",
    "    \"end_token\":3\n",
    "}\n",
    "]\n",
    "\n",
    "viz.render(tokens,spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method generate_html in module envtext.visualizers.span_visualizer:\n",
      "\n",
      "generate_html(tokens, spans, title='', **kwargs) method of envtext.visualizers.span_visualizer.SpanVisualizer instance\n",
      "    Render span types in text.\n",
      "    Spans are rendered per-token, this means that for each token, we check if it's part\n",
      "    of a span slice (a member of a span type) or a span start (the starting token of a\n",
      "    given span type).\n",
      "        tokens (list): Individual tokens in the text\n",
      "        spans (list): Individual entity spans and their start, end, label, kb_id and kb_url.\n",
      "        title (str / None): Document title set in Doc.user_data['title'].\n",
      "    \n",
      "    例如：\n",
      "        tokens = [\n",
      "    \n",
      "        ]\n",
      "        spans = [\n",
      "            \"start\":0,\n",
      "            \"end\":5,\n",
      "            \"label\":\"标签\",\n",
      "            \"kb_id\":\"\",\n",
      "            \"kb_url\":\"\"\n",
      "        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(viz.generate_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\2023Spring\\envtext\\src\\envtext测试.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/2023Spring/envtext/src/envtext%E6%B5%8B%E8%AF%95.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model(\u001b[39m\"\u001b[39;49m\u001b[39m哈哈哈哈\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\2023Spring\\envtext\\src\\envtext\\models\\model_base.py:467\u001b[0m, in \u001b[0;36mModelBase.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\u001b[39m*\u001b[39margs,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 467\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39m*\u001b[39;49margs,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\2023Spring\\envtext\\src\\envtext\\models\\model_base.py:432\u001b[0m, in \u001b[0;36mModelBase.predict\u001b[1;34m(self, texts, batch_size, max_length, auto_group, min_group_size, save_result, print_result, return_result, multiprocess, return_logits, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m             results\u001b[39m.\u001b[39mappend(p\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess,args,kwargs)\u001b[39m.\u001b[39mget())\n\u001b[0;32m    431\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m \u001b[39minput\u001b[39;49m,output : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpostprocess(\u001b[39minput\u001b[39;49m, output, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),input_list, outputs))\n\u001b[0;32m    435\u001b[0m \u001b[39mif\u001b[39;00m  ((print_result \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(texts) \u001b[39m<\u001b[39m batch_size) \u001b[39mor\u001b[39;00m (print_result \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m)) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisualizer :\n\u001b[0;32m    436\u001b[0m     \u001b[39mfor\u001b[39;00m text,result \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(texts, results):\n",
      "File \u001b[1;32md:\\2023Spring\\envtext\\src\\envtext\\models\\model_base.py:432\u001b[0m, in \u001b[0;36mModelBase.predict.<locals>.<lambda>\u001b[1;34m(input, output)\u001b[0m\n\u001b[0;32m    430\u001b[0m             results\u001b[39m.\u001b[39mappend(p\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess,args,kwargs)\u001b[39m.\u001b[39mget())\n\u001b[0;32m    431\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m \u001b[39minput\u001b[39m,output : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpostprocess(\u001b[39minput\u001b[39;49m, output, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),input_list, outputs))\n\u001b[0;32m    435\u001b[0m \u001b[39mif\u001b[39;00m  ((print_result \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(texts) \u001b[39m<\u001b[39m batch_size) \u001b[39mor\u001b[39;00m (print_result \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m)) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisualizer :\n\u001b[0;32m    436\u001b[0m     \u001b[39mfor\u001b[39;00m text,result \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(texts, results):\n",
      "File \u001b[1;32md:\\2023Spring\\envtext\\src\\envtext\\models\\bert_sa.py:62\u001b[0m, in \u001b[0;36mBertSA.postprocess\u001b[1;34m(self, text, logits, print_result, save_result)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpostprocess\u001b[39m(\u001b[39mself\u001b[39m,text, logits, print_result \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m ,save_result \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> 62\u001b[0m     logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39;49msqueeze()\n\u001b[0;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m print_result:\n\u001b[0;32m     64\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_per_sentence(text,logits)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0c64b729ee425e84fb65ebc411ddc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertConfig\n",
    "\n",
    "config= BertConfig.from_pretrained(Config.albert.pos_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'celtics1863/env-pos-ner-albert'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.albert.pos_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"line-height:2.5;\"/> \n",
       "        <mark class=\"cls\" style=\"background: #9467BD; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            土壤环境管理 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            65.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #FF9896; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            大气环境管理 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            5.8%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #D62728; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            科技与合作 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            4.4%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #98DF8A; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            生态环境执法 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            3.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #2CA02C; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            固废及化学品管理 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            3.9%</span>\n",
       "        </mark>\n",
       "        两个《办法》适用于行政主管部门在依法行使监督管理职责中，对建设用地和农用地土壤污染责任人不明确或者存在争议的情况下，开展的土壤污染责任人认定活动。这是当前土壤污染责任人认定工作的重点。涉及民事纠纷的责任人认定应当依据民事法律予以确定，不适用本《办法》。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from envtext import  BertNER,AlbertNER,Config,AlbertCLS\n",
    "# model = BertNER(\"../../../2022Spring/EnvText/models/pos/\",visualizer=\"pos\")\n",
    "model = AlbertCLS(Config.albert.policy_cls)\n",
    "# model = AlbertNER(\"../../envpos/envpos/files/pretrained_models/pos-albert/\",visualizer=\"pos\")\n",
    "res = model(\"两个《办法》适用于行政主管部门在依法行使监督管理职责中，对建设用地和农用地土壤污染责任人不明确或者存在争议的情况下，开展的土壤污染责任人认定活动。这是当前土壤污染责任人认定工作的重点。涉及民事纠纷的责任人认定应当依据民事法律予以确定，不适用本《办法》。\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"line-height:2.5;\"/> \n",
       "        <mark class=\"cls\" style=\"background: #9467BD; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            土壤环境管理 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            65.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #FF9896; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            大气环境管理 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            5.8%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #D62728; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            科技与合作 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            4.4%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #98DF8A; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            生态环境执法 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            3.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #2CA02C; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            固废及化学品管理 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            3.9%</span>\n",
       "        </mark>\n",
       "        两个《办法》适用于行政主管部门在依法行使监督管理职责中，对建设用地和农用地土壤污染责任人不明确或者存在争议的情况下，开展的土壤污染责任人认定活动。这是当前土壤污染责任人认定工作的重点。涉及民事纠纷的责任人认定应当依据民事法律予以确定，不适用本《办法》。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = \"两个《办法》适用于行政主管部门在依法行使监督管理职责中，对建设用地和农用地土壤污染责任人不明确或者存在争议的情况下，开展的土壤污染责任人认定活动。这是当前土壤污染责任人认定工作的重点。涉及民事纠纷的责任人认定应当依据民事法律予以确定，不适用本《办法》。\"\n",
    "model.visualizer.render(s,res[0],res[1],save_path =\"policy_albert.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('环保', 0.8425659537315369),\n",
       " ('生态环境保护', 0.7966809868812561),\n",
       " ('土壤环境保护', 0.7429764270782471),\n",
       " ('环境污染防治', 0.7383896708488464),\n",
       " ('生态保护', 0.6929160952568054),\n",
       " ('大气环境保护', 0.6914916634559631),\n",
       " ('应对气候变化', 0.6642681956291199),\n",
       " ('水污染防治', 0.6642411947250366),\n",
       " ('大气污染防治', 0.6606612801551819),\n",
       " ('环境管理', 0.6518533825874329)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from envtext.models import load_word2vec\n",
    "model = load_word2vec()\n",
    "model.most_similar('环境保护')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"line-height:2.5;\"/> \n",
       "        <mark class=\"cls\" style=\"background: #7F7F7F; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            光伏 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            91.4%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #F7B6D2; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            新能源 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            4.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #C5B0D5; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            电力 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #C49C94; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            风电 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.1%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #E377C2; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            燃气 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            0.3%</span>\n",
       "        </mark>\n",
       "        清洁能源基地建设对国家能源安全具有战略支撑作用。打造高质量的清洁能源基地的同时，也面临着一系列挑战，比如如何持续降低光储系统的度电成本、如何通过数字化的手段进一步提升运营与运维效率，如何更有效地提升光储系统的安全防护水平、如何在高比例新能源条件下实现稳定并网与消纳等。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from envtext import  BertNER,AlbertNER,Config,AlbertCLS\n",
    "# model = BertNER(\"../../../2022Spring/EnvText/models/pos/\",visualizer=\"pos\")\n",
    "# model = AlbertCLS(Config.albert.news_cls)\n",
    "# model = AlbertNER(\"../../envpos/envpos/files/pretrained_models/pos-albert/\",visualizer=\"pos\")\n",
    "res = model(\"清洁能源基地建设对国家能源安全具有战略支撑作用。打造高质量的清洁能源基地的同时，也面临着一系列挑战，比如如何持续降低光储系统的度电成本、如何通过数字化的手段进一步提升运营与运维效率，如何更有效地提升光储系统的安全防护水平、如何在高比例新能源条件下实现稳定并网与消纳等。\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"line-height:2.5;\"/> \n",
       "        <mark class=\"cls\" style=\"background: #7F7F7F; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            光伏 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            91.4%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #F7B6D2; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            新能源 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            4.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #C5B0D5; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            电力 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.9%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #C49C94; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            风电 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.1%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #E377C2; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            燃气 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            0.3%</span>\n",
       "        </mark>\n",
       "        清洁能源基地建设对国家能源安全具有战略支撑作用。打造高质量的清洁能源基地的同时，也面临着一系列挑战，比如如何持续降低光储系统的度电成本、如何通过数字化的手段进一步提升运营与运维效率，如何更有效地提升光储系统的安全防护水平、如何在高比例新能源条件下实现稳定并网与消纳等。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = \"清洁能源基地建设对国家能源安全具有战略支撑作用。打造高质量的清洁能源基地的同时，也面临着一系列挑战，比如如何持续降低光储系统的度电成本、如何通过数字化的手段进一步提升运营与运维效率，如何更有效地提升光储系统的安全防护水平、如何在高比例新能源条件下实现稳定并网与消纳等。\"\n",
    "model.visualizer.render(s,res[0],res[1],save_path =\"news_albert.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\2023Spring\\envtext\\src\\envtext\\models\\albert_cls.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = F.softmax(logits)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"line-height:2.5;\"/> \n",
       "        <mark class=\"cls\" style=\"background: #9EDAE5; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            气候变化 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            45.7%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #17BECF; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            温室效应 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            32.2%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #DBDB8D; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            全球变暖 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            14.4%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #BCBD22; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            自然环境 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.2%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #C7C7C7; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            生态环境 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.0%</span>\n",
       "        </mark>\n",
       "        在全球气候大会上，气候变化是各国政府都关心的话题"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from envtext import  BertNER,AlbertNER,Config,AlbertCLS\n",
    "# model = BertNER(\"../../../2022Spring/EnvText/models/pos/\",visualizer=\"pos\")\n",
    "# model = AlbertCLS(Config.albert.topic_cls)\n",
    "# model = AlbertNER(\"../../envpos/envpos/files/pretrained_models/pos-albert/\",visualizer=\"pos\")\n",
    "res = model(\"在全球气候大会上，气候变化是各国政府都关心的话题\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"line-height:2.5;\"/> \n",
       "        <mark class=\"cls\" style=\"background: #9EDAE5; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            气候变化 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            45.7%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #17BECF; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            温室效应 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            32.2%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #DBDB8D; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            全球变暖 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            14.4%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #BCBD22; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            自然环境 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.2%</span>\n",
       "        </mark>\n",
       "         \n",
       "        <mark class=\"cls\" style=\"background: #C7C7C7; text-indent:10em; ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em\"> \n",
       "            生态环境 \n",
       "            <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">\n",
       "            1.0%</span>\n",
       "        </mark>\n",
       "        在全球气候大会上，气候变化是各国政府都关心的话题"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = \"在全球气候大会上，气候变化是各国政府都关心的话题\"\n",
    "model.visualizer.render(s,res[0],res[1],save_path =\"topic_albert.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"Avg. Length\": 93.25221502248083,\n",
      "  \"_name_or_path\": \"celtics1863/env-pos-ner-albert\",\n",
      "  \"architectures\": [\n",
      "    \"AlbertCRF\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"contact\": \"bi.huaibin@foxmail.com\",\n",
      "  \"counter\": {\n",
      "    \"a\": 10754,\n",
      "    \"act\": 11596,\n",
      "    \"animal\": 1889,\n",
      "    \"b\": 10174,\n",
      "    \"c\": 1733,\n",
      "    \"code\": 1569,\n",
      "    \"com\": 3688,\n",
      "    \"conj\": 42141,\n",
      "    \"d\": 44861,\n",
      "    \"desease\": 886,\n",
      "    \"doc\": 5800,\n",
      "    \"env\": 23139,\n",
      "    \"event\": 974,\n",
      "    \"f\": 15266,\n",
      "    \"gov\": 7317,\n",
      "    \"group\": 7788,\n",
      "    \"hy\": 5660,\n",
      "    \"ins\": 4818,\n",
      "    \"loc\": 13678,\n",
      "    \"m\": 20601,\n",
      "    \"means\": 3243,\n",
      "    \"med\": 8403,\n",
      "    \"meet\": 1445,\n",
      "    \"microbe\": 742,\n",
      "    \"n\": 39522,\n",
      "    \"ord\": 4903,\n",
      "    \"org\": 768,\n",
      "    \"p\": 25511,\n",
      "    \"per\": 4878,\n",
      "    \"phe\": 3516,\n",
      "    \"plant\": 923,\n",
      "    \"pol\": 11919,\n",
      "    \"policy\": 6000,\n",
      "    \"pro\": 6056,\n",
      "    \"q\": 7650,\n",
      "    \"r\": 16069,\n",
      "    \"time\": 9603,\n",
      "    \"u\": 44563,\n",
      "    \"v\": 101116,\n",
      "    \"vn\": 21264,\n",
      "    \"w\": 75103,\n",
      "    \"xc\": 352\n",
      "  },\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"entities\": [\n",
      "    \"doc\",\n",
      "    \"d\",\n",
      "    \"v\",\n",
      "    \"meet\",\n",
      "    \"w\",\n",
      "    \"conj\",\n",
      "    \"group\",\n",
      "    \"env\",\n",
      "    \"time\",\n",
      "    \"u\",\n",
      "    \"gov\",\n",
      "    \"act\",\n",
      "    \"a\",\n",
      "    \"n\",\n",
      "    \"vn\",\n",
      "    \"loc\",\n",
      "    \"event\",\n",
      "    \"pro\",\n",
      "    \"per\",\n",
      "    \"med\",\n",
      "    \"c\",\n",
      "    \"p\",\n",
      "    \"phe\",\n",
      "    \"m\",\n",
      "    \"f\",\n",
      "    \"policy\",\n",
      "    \"ord\",\n",
      "    \"com\",\n",
      "    \"r\",\n",
      "    \"pol\",\n",
      "    \"desease\",\n",
      "    \"b\",\n",
      "    \"q\",\n",
      "    \"org\",\n",
      "    \"ins\",\n",
      "    \"means\",\n",
      "    \"hy\",\n",
      "    \"microbe\",\n",
      "    \"xc\",\n",
      "    \"code\",\n",
      "    \"plant\",\n",
      "    \"animal\"\n",
      "  ],\n",
      "  \"entity2id\": {\n",
      "    \"a\": 12,\n",
      "    \"act\": 11,\n",
      "    \"animal\": 41,\n",
      "    \"b\": 31,\n",
      "    \"c\": 20,\n",
      "    \"code\": 39,\n",
      "    \"com\": 27,\n",
      "    \"conj\": 5,\n",
      "    \"d\": 1,\n",
      "    \"desease\": 30,\n",
      "    \"doc\": 0,\n",
      "    \"env\": 7,\n",
      "    \"event\": 16,\n",
      "    \"f\": 24,\n",
      "    \"gov\": 10,\n",
      "    \"group\": 6,\n",
      "    \"hy\": 36,\n",
      "    \"ins\": 34,\n",
      "    \"loc\": 15,\n",
      "    \"m\": 23,\n",
      "    \"means\": 35,\n",
      "    \"med\": 19,\n",
      "    \"meet\": 3,\n",
      "    \"microbe\": 37,\n",
      "    \"n\": 13,\n",
      "    \"ord\": 26,\n",
      "    \"org\": 33,\n",
      "    \"p\": 21,\n",
      "    \"per\": 18,\n",
      "    \"phe\": 22,\n",
      "    \"plant\": 40,\n",
      "    \"pol\": 29,\n",
      "    \"policy\": 25,\n",
      "    \"pro\": 17,\n",
      "    \"q\": 32,\n",
      "    \"r\": 28,\n",
      "    \"time\": 8,\n",
      "    \"u\": 9,\n",
      "    \"v\": 2,\n",
      "    \"vn\": 14,\n",
      "    \"w\": 4,\n",
      "    \"xc\": 38\n",
      "  },\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 312,\n",
      "  \"id2entity\": {\n",
      "    \"0\": \"doc\",\n",
      "    \"1\": \"d\",\n",
      "    \"10\": \"gov\",\n",
      "    \"11\": \"act\",\n",
      "    \"12\": \"a\",\n",
      "    \"13\": \"n\",\n",
      "    \"14\": \"vn\",\n",
      "    \"15\": \"loc\",\n",
      "    \"16\": \"event\",\n",
      "    \"17\": \"pro\",\n",
      "    \"18\": \"per\",\n",
      "    \"19\": \"med\",\n",
      "    \"2\": \"v\",\n",
      "    \"20\": \"c\",\n",
      "    \"21\": \"p\",\n",
      "    \"22\": \"phe\",\n",
      "    \"23\": \"m\",\n",
      "    \"24\": \"f\",\n",
      "    \"25\": \"policy\",\n",
      "    \"26\": \"ord\",\n",
      "    \"27\": \"com\",\n",
      "    \"28\": \"r\",\n",
      "    \"29\": \"pol\",\n",
      "    \"3\": \"meet\",\n",
      "    \"30\": \"desease\",\n",
      "    \"31\": \"b\",\n",
      "    \"32\": \"q\",\n",
      "    \"33\": \"org\",\n",
      "    \"34\": \"ins\",\n",
      "    \"35\": \"means\",\n",
      "    \"36\": \"hy\",\n",
      "    \"37\": \"microbe\",\n",
      "    \"38\": \"xc\",\n",
      "    \"39\": \"code\",\n",
      "    \"4\": \"w\",\n",
      "    \"40\": \"plant\",\n",
      "    \"41\": \"animal\",\n",
      "    \"5\": \"conj\",\n",
      "    \"6\": \"group\",\n",
      "    \"7\": \"env\",\n",
      "    \"8\": \"time\",\n",
      "    \"9\": \"u\"\n",
      "  },\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-doc\",\n",
      "    \"2\": \"I-doc\",\n",
      "    \"3\": \"E-doc\",\n",
      "    \"4\": \"S-doc\",\n",
      "    \"5\": \"B-d\",\n",
      "    \"6\": \"I-d\",\n",
      "    \"7\": \"E-d\",\n",
      "    \"8\": \"S-d\",\n",
      "    \"9\": \"B-v\",\n",
      "    \"10\": \"I-v\",\n",
      "    \"11\": \"E-v\",\n",
      "    \"12\": \"S-v\",\n",
      "    \"13\": \"B-meet\",\n",
      "    \"14\": \"I-meet\",\n",
      "    \"15\": \"E-meet\",\n",
      "    \"16\": \"S-meet\",\n",
      "    \"17\": \"B-w\",\n",
      "    \"18\": \"I-w\",\n",
      "    \"19\": \"E-w\",\n",
      "    \"20\": \"S-w\",\n",
      "    \"21\": \"B-conj\",\n",
      "    \"22\": \"I-conj\",\n",
      "    \"23\": \"E-conj\",\n",
      "    \"24\": \"S-conj\",\n",
      "    \"25\": \"B-group\",\n",
      "    \"26\": \"I-group\",\n",
      "    \"27\": \"E-group\",\n",
      "    \"28\": \"S-group\",\n",
      "    \"29\": \"B-env\",\n",
      "    \"30\": \"I-env\",\n",
      "    \"31\": \"E-env\",\n",
      "    \"32\": \"S-env\",\n",
      "    \"33\": \"B-time\",\n",
      "    \"34\": \"I-time\",\n",
      "    \"35\": \"E-time\",\n",
      "    \"36\": \"S-time\",\n",
      "    \"37\": \"B-u\",\n",
      "    \"38\": \"I-u\",\n",
      "    \"39\": \"E-u\",\n",
      "    \"40\": \"S-u\",\n",
      "    \"41\": \"B-gov\",\n",
      "    \"42\": \"I-gov\",\n",
      "    \"43\": \"E-gov\",\n",
      "    \"44\": \"S-gov\",\n",
      "    \"45\": \"B-act\",\n",
      "    \"46\": \"I-act\",\n",
      "    \"47\": \"E-act\",\n",
      "    \"48\": \"S-act\",\n",
      "    \"49\": \"B-a\",\n",
      "    \"50\": \"I-a\",\n",
      "    \"51\": \"E-a\",\n",
      "    \"52\": \"S-a\",\n",
      "    \"53\": \"B-n\",\n",
      "    \"54\": \"I-n\",\n",
      "    \"55\": \"E-n\",\n",
      "    \"56\": \"S-n\",\n",
      "    \"57\": \"B-vn\",\n",
      "    \"58\": \"I-vn\",\n",
      "    \"59\": \"E-vn\",\n",
      "    \"60\": \"S-vn\",\n",
      "    \"61\": \"B-loc\",\n",
      "    \"62\": \"I-loc\",\n",
      "    \"63\": \"E-loc\",\n",
      "    \"64\": \"S-loc\",\n",
      "    \"65\": \"B-event\",\n",
      "    \"66\": \"I-event\",\n",
      "    \"67\": \"E-event\",\n",
      "    \"68\": \"S-event\",\n",
      "    \"69\": \"B-pro\",\n",
      "    \"70\": \"I-pro\",\n",
      "    \"71\": \"E-pro\",\n",
      "    \"72\": \"S-pro\",\n",
      "    \"73\": \"B-per\",\n",
      "    \"74\": \"I-per\",\n",
      "    \"75\": \"E-per\",\n",
      "    \"76\": \"S-per\",\n",
      "    \"77\": \"B-med\",\n",
      "    \"78\": \"I-med\",\n",
      "    \"79\": \"E-med\",\n",
      "    \"80\": \"S-med\",\n",
      "    \"81\": \"B-c\",\n",
      "    \"82\": \"I-c\",\n",
      "    \"83\": \"E-c\",\n",
      "    \"84\": \"S-c\",\n",
      "    \"85\": \"B-p\",\n",
      "    \"86\": \"I-p\",\n",
      "    \"87\": \"E-p\",\n",
      "    \"88\": \"S-p\",\n",
      "    \"89\": \"B-phe\",\n",
      "    \"90\": \"I-phe\",\n",
      "    \"91\": \"E-phe\",\n",
      "    \"92\": \"S-phe\",\n",
      "    \"93\": \"B-m\",\n",
      "    \"94\": \"I-m\",\n",
      "    \"95\": \"E-m\",\n",
      "    \"96\": \"S-m\",\n",
      "    \"97\": \"B-f\",\n",
      "    \"98\": \"I-f\",\n",
      "    \"99\": \"E-f\",\n",
      "    \"100\": \"S-f\",\n",
      "    \"101\": \"B-policy\",\n",
      "    \"102\": \"I-policy\",\n",
      "    \"103\": \"E-policy\",\n",
      "    \"104\": \"S-policy\",\n",
      "    \"105\": \"B-ord\",\n",
      "    \"106\": \"I-ord\",\n",
      "    \"107\": \"E-ord\",\n",
      "    \"108\": \"S-ord\",\n",
      "    \"109\": \"B-com\",\n",
      "    \"110\": \"I-com\",\n",
      "    \"111\": \"E-com\",\n",
      "    \"112\": \"S-com\",\n",
      "    \"113\": \"B-r\",\n",
      "    \"114\": \"I-r\",\n",
      "    \"115\": \"E-r\",\n",
      "    \"116\": \"S-r\",\n",
      "    \"117\": \"B-pol\",\n",
      "    \"118\": \"I-pol\",\n",
      "    \"119\": \"E-pol\",\n",
      "    \"120\": \"S-pol\",\n",
      "    \"121\": \"B-desease\",\n",
      "    \"122\": \"I-desease\",\n",
      "    \"123\": \"E-desease\",\n",
      "    \"124\": \"S-desease\",\n",
      "    \"125\": \"B-b\",\n",
      "    \"126\": \"I-b\",\n",
      "    \"127\": \"E-b\",\n",
      "    \"128\": \"S-b\",\n",
      "    \"129\": \"B-q\",\n",
      "    \"130\": \"I-q\",\n",
      "    \"131\": \"E-q\",\n",
      "    \"132\": \"S-q\",\n",
      "    \"133\": \"B-org\",\n",
      "    \"134\": \"I-org\",\n",
      "    \"135\": \"E-org\",\n",
      "    \"136\": \"S-org\",\n",
      "    \"137\": \"B-ins\",\n",
      "    \"138\": \"I-ins\",\n",
      "    \"139\": \"E-ins\",\n",
      "    \"140\": \"S-ins\",\n",
      "    \"141\": \"B-means\",\n",
      "    \"142\": \"I-means\",\n",
      "    \"143\": \"E-means\",\n",
      "    \"144\": \"S-means\",\n",
      "    \"145\": \"B-hy\",\n",
      "    \"146\": \"I-hy\",\n",
      "    \"147\": \"E-hy\",\n",
      "    \"148\": \"S-hy\",\n",
      "    \"149\": \"B-microbe\",\n",
      "    \"150\": \"I-microbe\",\n",
      "    \"151\": \"E-microbe\",\n",
      "    \"152\": \"S-microbe\",\n",
      "    \"153\": \"B-xc\",\n",
      "    \"154\": \"I-xc\",\n",
      "    \"155\": \"E-xc\",\n",
      "    \"156\": \"S-xc\",\n",
      "    \"157\": \"B-code\",\n",
      "    \"158\": \"I-code\",\n",
      "    \"159\": \"E-code\",\n",
      "    \"160\": \"S-code\",\n",
      "    \"161\": \"B-plant\",\n",
      "    \"162\": \"I-plant\",\n",
      "    \"163\": \"E-plant\",\n",
      "    \"164\": \"S-plant\",\n",
      "    \"165\": \"B-animal\",\n",
      "    \"166\": \"I-animal\",\n",
      "    \"167\": \"E-animal\",\n",
      "    \"168\": \"S-animal\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 1248,\n",
      "  \"jieba\": false,\n",
      "  \"key_metric\": \"macro_f1\",\n",
      "  \"label2id\": {\n",
      "    \"B-a\": 49,\n",
      "    \"B-act\": 45,\n",
      "    \"B-animal\": 165,\n",
      "    \"B-b\": 125,\n",
      "    \"B-c\": 81,\n",
      "    \"B-code\": 157,\n",
      "    \"B-com\": 109,\n",
      "    \"B-conj\": 21,\n",
      "    \"B-d\": 5,\n",
      "    \"B-desease\": 121,\n",
      "    \"B-doc\": 1,\n",
      "    \"B-env\": 29,\n",
      "    \"B-event\": 65,\n",
      "    \"B-f\": 97,\n",
      "    \"B-gov\": 41,\n",
      "    \"B-group\": 25,\n",
      "    \"B-hy\": 145,\n",
      "    \"B-ins\": 137,\n",
      "    \"B-loc\": 61,\n",
      "    \"B-m\": 93,\n",
      "    \"B-means\": 141,\n",
      "    \"B-med\": 77,\n",
      "    \"B-meet\": 13,\n",
      "    \"B-microbe\": 149,\n",
      "    \"B-n\": 53,\n",
      "    \"B-ord\": 105,\n",
      "    \"B-org\": 133,\n",
      "    \"B-p\": 85,\n",
      "    \"B-per\": 73,\n",
      "    \"B-phe\": 89,\n",
      "    \"B-plant\": 161,\n",
      "    \"B-pol\": 117,\n",
      "    \"B-policy\": 101,\n",
      "    \"B-pro\": 69,\n",
      "    \"B-q\": 129,\n",
      "    \"B-r\": 113,\n",
      "    \"B-time\": 33,\n",
      "    \"B-u\": 37,\n",
      "    \"B-v\": 9,\n",
      "    \"B-vn\": 57,\n",
      "    \"B-w\": 17,\n",
      "    \"B-xc\": 153,\n",
      "    \"E-a\": 51,\n",
      "    \"E-act\": 47,\n",
      "    \"E-animal\": 167,\n",
      "    \"E-b\": 127,\n",
      "    \"E-c\": 83,\n",
      "    \"E-code\": 159,\n",
      "    \"E-com\": 111,\n",
      "    \"E-conj\": 23,\n",
      "    \"E-d\": 7,\n",
      "    \"E-desease\": 123,\n",
      "    \"E-doc\": 3,\n",
      "    \"E-env\": 31,\n",
      "    \"E-event\": 67,\n",
      "    \"E-f\": 99,\n",
      "    \"E-gov\": 43,\n",
      "    \"E-group\": 27,\n",
      "    \"E-hy\": 147,\n",
      "    \"E-ins\": 139,\n",
      "    \"E-loc\": 63,\n",
      "    \"E-m\": 95,\n",
      "    \"E-means\": 143,\n",
      "    \"E-med\": 79,\n",
      "    \"E-meet\": 15,\n",
      "    \"E-microbe\": 151,\n",
      "    \"E-n\": 55,\n",
      "    \"E-ord\": 107,\n",
      "    \"E-org\": 135,\n",
      "    \"E-p\": 87,\n",
      "    \"E-per\": 75,\n",
      "    \"E-phe\": 91,\n",
      "    \"E-plant\": 163,\n",
      "    \"E-pol\": 119,\n",
      "    \"E-policy\": 103,\n",
      "    \"E-pro\": 71,\n",
      "    \"E-q\": 131,\n",
      "    \"E-r\": 115,\n",
      "    \"E-time\": 35,\n",
      "    \"E-u\": 39,\n",
      "    \"E-v\": 11,\n",
      "    \"E-vn\": 59,\n",
      "    \"E-w\": 19,\n",
      "    \"E-xc\": 155,\n",
      "    \"I-a\": 50,\n",
      "    \"I-act\": 46,\n",
      "    \"I-animal\": 166,\n",
      "    \"I-b\": 126,\n",
      "    \"I-c\": 82,\n",
      "    \"I-code\": 158,\n",
      "    \"I-com\": 110,\n",
      "    \"I-conj\": 22,\n",
      "    \"I-d\": 6,\n",
      "    \"I-desease\": 122,\n",
      "    \"I-doc\": 2,\n",
      "    \"I-env\": 30,\n",
      "    \"I-event\": 66,\n",
      "    \"I-f\": 98,\n",
      "    \"I-gov\": 42,\n",
      "    \"I-group\": 26,\n",
      "    \"I-hy\": 146,\n",
      "    \"I-ins\": 138,\n",
      "    \"I-loc\": 62,\n",
      "    \"I-m\": 94,\n",
      "    \"I-means\": 142,\n",
      "    \"I-med\": 78,\n",
      "    \"I-meet\": 14,\n",
      "    \"I-microbe\": 150,\n",
      "    \"I-n\": 54,\n",
      "    \"I-ord\": 106,\n",
      "    \"I-org\": 134,\n",
      "    \"I-p\": 86,\n",
      "    \"I-per\": 74,\n",
      "    \"I-phe\": 90,\n",
      "    \"I-plant\": 162,\n",
      "    \"I-pol\": 118,\n",
      "    \"I-policy\": 102,\n",
      "    \"I-pro\": 70,\n",
      "    \"I-q\": 130,\n",
      "    \"I-r\": 114,\n",
      "    \"I-time\": 34,\n",
      "    \"I-u\": 38,\n",
      "    \"I-v\": 10,\n",
      "    \"I-vn\": 58,\n",
      "    \"I-w\": 18,\n",
      "    \"I-xc\": 154,\n",
      "    \"O\": 0,\n",
      "    \"S-a\": 52,\n",
      "    \"S-act\": 48,\n",
      "    \"S-animal\": 168,\n",
      "    \"S-b\": 128,\n",
      "    \"S-c\": 84,\n",
      "    \"S-code\": 160,\n",
      "    \"S-com\": 112,\n",
      "    \"S-conj\": 24,\n",
      "    \"S-d\": 8,\n",
      "    \"S-desease\": 124,\n",
      "    \"S-doc\": 4,\n",
      "    \"S-env\": 32,\n",
      "    \"S-event\": 68,\n",
      "    \"S-f\": 100,\n",
      "    \"S-gov\": 44,\n",
      "    \"S-group\": 28,\n",
      "    \"S-hy\": 148,\n",
      "    \"S-ins\": 140,\n",
      "    \"S-loc\": 64,\n",
      "    \"S-m\": 96,\n",
      "    \"S-means\": 144,\n",
      "    \"S-med\": 80,\n",
      "    \"S-meet\": 16,\n",
      "    \"S-microbe\": 152,\n",
      "    \"S-n\": 56,\n",
      "    \"S-ord\": 108,\n",
      "    \"S-org\": 136,\n",
      "    \"S-p\": 88,\n",
      "    \"S-per\": 76,\n",
      "    \"S-phe\": 92,\n",
      "    \"S-plant\": 164,\n",
      "    \"S-pol\": 120,\n",
      "    \"S-policy\": 104,\n",
      "    \"S-pro\": 72,\n",
      "    \"S-q\": 132,\n",
      "    \"S-r\": 116,\n",
      "    \"S-time\": 36,\n",
      "    \"S-u\": 40,\n",
      "    \"S-v\": 12,\n",
      "    \"S-vn\": 60,\n",
      "    \"S-w\": 20,\n",
      "    \"S-xc\": 156\n",
      "  },\n",
      "  \"labels\": [\n",
      "    \"O\",\n",
      "    \"B-doc\",\n",
      "    \"I-doc\",\n",
      "    \"E-doc\",\n",
      "    \"S-doc\",\n",
      "    \"B-d\",\n",
      "    \"I-d\",\n",
      "    \"E-d\",\n",
      "    \"S-d\",\n",
      "    \"B-v\",\n",
      "    \"I-v\",\n",
      "    \"E-v\",\n",
      "    \"S-v\",\n",
      "    \"B-meet\",\n",
      "    \"I-meet\",\n",
      "    \"E-meet\",\n",
      "    \"S-meet\",\n",
      "    \"B-w\",\n",
      "    \"I-w\",\n",
      "    \"E-w\",\n",
      "    \"S-w\",\n",
      "    \"B-conj\",\n",
      "    \"I-conj\",\n",
      "    \"E-conj\",\n",
      "    \"S-conj\",\n",
      "    \"B-group\",\n",
      "    \"I-group\",\n",
      "    \"E-group\",\n",
      "    \"S-group\",\n",
      "    \"B-env\",\n",
      "    \"I-env\",\n",
      "    \"E-env\",\n",
      "    \"S-env\",\n",
      "    \"B-time\",\n",
      "    \"I-time\",\n",
      "    \"E-time\",\n",
      "    \"S-time\",\n",
      "    \"B-u\",\n",
      "    \"I-u\",\n",
      "    \"E-u\",\n",
      "    \"S-u\",\n",
      "    \"B-gov\",\n",
      "    \"I-gov\",\n",
      "    \"E-gov\",\n",
      "    \"S-gov\",\n",
      "    \"B-act\",\n",
      "    \"I-act\",\n",
      "    \"E-act\",\n",
      "    \"S-act\",\n",
      "    \"B-a\",\n",
      "    \"I-a\",\n",
      "    \"E-a\",\n",
      "    \"S-a\",\n",
      "    \"B-n\",\n",
      "    \"I-n\",\n",
      "    \"E-n\",\n",
      "    \"S-n\",\n",
      "    \"B-vn\",\n",
      "    \"I-vn\",\n",
      "    \"E-vn\",\n",
      "    \"S-vn\",\n",
      "    \"B-loc\",\n",
      "    \"I-loc\",\n",
      "    \"E-loc\",\n",
      "    \"S-loc\",\n",
      "    \"B-event\",\n",
      "    \"I-event\",\n",
      "    \"E-event\",\n",
      "    \"S-event\",\n",
      "    \"B-pro\",\n",
      "    \"I-pro\",\n",
      "    \"E-pro\",\n",
      "    \"S-pro\",\n",
      "    \"B-per\",\n",
      "    \"I-per\",\n",
      "    \"E-per\",\n",
      "    \"S-per\",\n",
      "    \"B-med\",\n",
      "    \"I-med\",\n",
      "    \"E-med\",\n",
      "    \"S-med\",\n",
      "    \"B-c\",\n",
      "    \"I-c\",\n",
      "    \"E-c\",\n",
      "    \"S-c\",\n",
      "    \"B-p\",\n",
      "    \"I-p\",\n",
      "    \"E-p\",\n",
      "    \"S-p\",\n",
      "    \"B-phe\",\n",
      "    \"I-phe\",\n",
      "    \"E-phe\",\n",
      "    \"S-phe\",\n",
      "    \"B-m\",\n",
      "    \"I-m\",\n",
      "    \"E-m\",\n",
      "    \"S-m\",\n",
      "    \"B-f\",\n",
      "    \"I-f\",\n",
      "    \"E-f\",\n",
      "    \"S-f\",\n",
      "    \"B-policy\",\n",
      "    \"I-policy\",\n",
      "    \"E-policy\",\n",
      "    \"S-policy\",\n",
      "    \"B-ord\",\n",
      "    \"I-ord\",\n",
      "    \"E-ord\",\n",
      "    \"S-ord\",\n",
      "    \"B-com\",\n",
      "    \"I-com\",\n",
      "    \"E-com\",\n",
      "    \"S-com\",\n",
      "    \"B-r\",\n",
      "    \"I-r\",\n",
      "    \"E-r\",\n",
      "    \"S-r\",\n",
      "    \"B-pol\",\n",
      "    \"I-pol\",\n",
      "    \"E-pol\",\n",
      "    \"S-pol\",\n",
      "    \"B-desease\",\n",
      "    \"I-desease\",\n",
      "    \"E-desease\",\n",
      "    \"S-desease\",\n",
      "    \"B-b\",\n",
      "    \"I-b\",\n",
      "    \"E-b\",\n",
      "    \"S-b\",\n",
      "    \"B-q\",\n",
      "    \"I-q\",\n",
      "    \"E-q\",\n",
      "    \"S-q\",\n",
      "    \"B-org\",\n",
      "    \"I-org\",\n",
      "    \"E-org\",\n",
      "    \"S-org\",\n",
      "    \"B-ins\",\n",
      "    \"I-ins\",\n",
      "    \"E-ins\",\n",
      "    \"S-ins\",\n",
      "    \"B-means\",\n",
      "    \"I-means\",\n",
      "    \"E-means\",\n",
      "    \"S-means\",\n",
      "    \"B-hy\",\n",
      "    \"I-hy\",\n",
      "    \"E-hy\",\n",
      "    \"S-hy\",\n",
      "    \"B-microbe\",\n",
      "    \"I-microbe\",\n",
      "    \"E-microbe\",\n",
      "    \"S-microbe\",\n",
      "    \"B-xc\",\n",
      "    \"I-xc\",\n",
      "    \"E-xc\",\n",
      "    \"S-xc\",\n",
      "    \"B-code\",\n",
      "    \"I-code\",\n",
      "    \"E-code\",\n",
      "    \"S-code\",\n",
      "    \"B-plant\",\n",
      "    \"I-plant\",\n",
      "    \"E-plant\",\n",
      "    \"S-plant\",\n",
      "    \"B-animal\",\n",
      "    \"I-animal\",\n",
      "    \"E-animal\",\n",
      "    \"S-animal\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"liscence\": \"Apache Lisence\",\n",
      "  \"max_length\": 510,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"mirror\": \"https://mirror.nju.edu.cn/hugging-face-models\",\n",
      "  \"model_type\": \"bert\",\n",
      "  \"ner_encoding\": \"BIOES\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_entities\": 42,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"num_test_texts\": 0,\n",
      "  \"num_train_texts\": 24114,\n",
      "  \"num_valid_texts\": 6134,\n",
      "  \"package\": \"envtext\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"resampling\": 4,\n",
      "  \"resampling_ratio\": 4,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"visualizer\": \"pos\",\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorCompare.cpp:333.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"line-height:2.5;\">\n",
       "         \n",
       "        在 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">p/介词</span>\n",
       "     \n",
       "        全球气候大会 \n",
       "        <span style=\"font-size: 0.8em; background: lightcoral;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">会议</span>\n",
       "     \n",
       "        上 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">f/方位词</span>\n",
       "     \n",
       "        ， \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">w/标点</span>\n",
       "     \n",
       "        气候变化 \n",
       "        <span style=\"font-size: 0.8em; background: lightgreen;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">环境现象</span>\n",
       "     \n",
       "        是 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">v/动词</span>\n",
       "     \n",
       "        各国政府 \n",
       "        <span style=\"font-size: 0.8em; background: lightcoral;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">政府</span>\n",
       "     \n",
       "        都 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">d/副词</span>\n",
       "     \n",
       "        关心 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">v/动词</span>\n",
       "     \n",
       "        的 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">u/助词</span>\n",
       "     \n",
       "        话题 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">n/名词</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from envtext import  BertNER,AlbertNER,Config\n",
    "# model = BertNER(\"../../../2022Spring/EnvText/models/pos/\",visualizer=\"pos\")\n",
    "model = AlbertNER(Config.albert.pos_ner,visualizer=\"pos\")\n",
    "# model = AlbertNER(\"../../envpos/envpos/files/pretrained_models/pos-albert/\",visualizer=\"pos\")\n",
    "res = model(\"在全球气候大会上，气候变化是各国政府都关心的话题\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"line-height:2.5;\">\n",
       "         \n",
       "        在 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">p/介词</span>\n",
       "     \n",
       "        全球气候大会 \n",
       "        <span style=\"font-size: 0.8em; background: lightcoral;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">会议</span>\n",
       "     \n",
       "        上 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">f/方位词</span>\n",
       "     \n",
       "        ， \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">w/标点</span>\n",
       "     \n",
       "        气候变化 \n",
       "        <span style=\"font-size: 0.8em; background: lightgreen;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">环境现象</span>\n",
       "     \n",
       "        是 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">v/动词</span>\n",
       "     \n",
       "        各国政府 \n",
       "        <span style=\"font-size: 0.8em; background: lightcoral;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">政府</span>\n",
       "     \n",
       "        都 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">d/副词</span>\n",
       "     \n",
       "        关心 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">v/动词</span>\n",
       "     \n",
       "        的 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">u/助词</span>\n",
       "     \n",
       "        话题 \n",
       "        <span style=\"font-size: 0.8em; background: lightblue;  font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-right: 0.5rem\">n/名词</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = \"在全球气候大会上，气候变化是各国政府都关心的话题\"\n",
    "model.visualizer.render(s,res[0],res[1],save_path =\"pos_albert.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\flatbuffers\\compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:29: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  _PIL_INTERPOLATION_METHODS['hamming'] = pil_image.HAMMING\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:31: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  _PIL_INTERPOLATION_METHODS['box'] = pil_image.BOX\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:34: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  _PIL_INTERPOLATION_METHODS['lanczos'] = pil_image.LANCZOS\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n",
      "d:\\2023Spring\\envtext\\src\\envtext\\tokenizers\\onehot_tokenizer.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Iterable,OrderedDict\n"
     ]
    }
   ],
   "source": [
    "from envtext import Bert2Vec,Config\n",
    "model = Bert2Vec(Config.bert.bert_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at celtics1863/env-bert-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at celtics1863/env-bert-chinese and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "model.add_words(\n",
    "    [\n",
    "        \"环境污染\",\n",
    "        \"水污染\",\n",
    "        \"大气污染\",\n",
    "        \"北京市\",\n",
    "        \"上海市\",\n",
    "        \"兰州市\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('兰州市', 0.8755860328674316),\n",
       " ('北京市', 0.7335232496261597),\n",
       " ('上海市', 0.7241109013557434),\n",
       " ('大气污染', 0.471857488155365),\n",
       " ('水污染', 0.4557272493839264)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"郑州市\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envtext.models import load_word2vec\n",
    "model = load_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.304651  ,  -3.1560812 ,   6.4074125 ,  -3.6906316 ,\n",
       "        -1.4232658 ,   4.7912726 ,  -0.8003967 ,   4.0756955 ,\n",
       "        -2.7932549 ,   4.029449  ,  -1.9410586 ,  -6.844793  ,\n",
       "        -8.859059  ,  -0.93295586,   6.1359916 ,   1.9588425 ,\n",
       "         2.625194  ,  -4.3848248 ,  -6.4393744 ,   6.0373173 ,\n",
       "        -6.155831  ,  -6.4436955 ,   5.107795  , -11.209849  ,\n",
       "         0.04123919,   1.286314  , -11.320914  ,  -6.475419  ,\n",
       "         0.8528328 ,  -6.1932034 ,   2.0541244 ,  -3.3850324 ,\n",
       "         4.284287  ,  -7.197888  ,  -2.6205683 ,   0.31572345,\n",
       "         5.227246  ,   3.903521  ,  -2.5171268 ,   2.4655945 ,\n",
       "        -5.5421305 ,   5.5044537 ,   6.984615  ,  -7.6862364 ,\n",
       "         0.87583727,   0.03240405,   2.3616972 ,  -0.9396556 ,\n",
       "         3.9617348 ,   0.6690969 , -10.708663  ,  -2.8534212 ,\n",
       "        -0.8638448 ,  12.048176  ,   5.5968127 ,  -6.834452  ,\n",
       "         6.9515004 ,   3.948555  ,  -4.527055  ,   4.389503  ,\n",
       "        -0.47533572,   6.79178   ,  -0.8689579 ,  -2.7712438 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_vector('环境保护')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 128, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'architectures': None, 'finetuning_task': None, 'id2label': {0: 'LABEL_0'}, 'label2id': {'LABEL_0': 0}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '', 'transformers_version': '4.22.1', 'package': 'envtext', 'liscence': 'Apache Lisence', 'contact': 'bi.huaibin@foxmail.com', 'mirror': 'https://mirror.nju.edu.cn/hugging-face-models', 'model_name': 'lstm', 'labels': [], 'entities': [], 'num_entities': [], 'hidden_size': 512, 'num_layers': 3, 'onehot_embed': False, 'embed_size': 512, 'token_method': 'word2vec', 'word2vec_path': None, 'vocab_path': None, 'truncation': True, 'padding': True, 'remake_vocab': True, 'visualizer': 'entity', 'key_metric': 'macro_f1', 'model_type': '', 'path': '../../pos数据集.txt', 'task': 'NER', 'format': 'text2', 'sampler': 1, 'split': 0.5, 'label_as_key': False, 'label_inline': True, 'ner_encoding': 'BIOES', 'sep': ' ', 'dataset': 'dataset', 'train': 'train', 'valid': 'valid', 'test': 'test', 'text': 'text', 'label': 'label', 'entity_label': 'label', 'loc': 'loc'}\n",
      "******* 读取数据集成功 *******\n"
     ]
    }
   ],
   "source": [
    "from envtext import Bert2Vec,Config,RNNNER,load_dataset\n",
    "model = RNNNER(num_labels=1,token_method=\"onehot\")\n",
    "model.load_dataset(\"../../pos数据集.txt\", format=\"text2\",label_inline=True,ner_encoding=\"BIOES\",task=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06431569528606812]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_reports[\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练集 Tokenizing 进度: 100%|██████████| 2077/2077 [00:00<00:00, 2540.73it/s]\n",
      "验证集 Tokenizing 进度: 100%|██████████| 2123/2123 [00:01<00:00, 1680.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******   开始训练   *******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss is 1077.5303: 100%|██████████| 260/260 [00:54<00:00,  4.75it/s]\n",
      "c:\\Users\\17938\\.conda\\envs\\torch\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorCompare.cpp:333.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "Valid Loss is 134.6632: 100%|██████████| 266/266 [00:23<00:00, 11.20it/s] \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to list.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\2023Spring\\envtext\\src\\envtext测试.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/2023Spring/envtext/src/envtext%E6%B5%8B%E8%AF%95.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(epoch\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\n",
      "File \u001b[1;32md:\\2023Spring\\envtext\\src\\envtext\\models\\rnn_base.py:529\u001b[0m, in \u001b[0;36mRNNBase.train\u001b[1;34m(self, my_datasets, epoch, batch_size, learning_rate, save_path, checkpoint_path, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m valid_report \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_per_step(valid_dataloader)\n\u001b[0;32m    527\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_valid_reports(valid_report)\n\u001b[1;32m--> 529\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_report(valid_report)\n\u001b[0;32m    531\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_metric \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_metric \u001b[39min\u001b[39;00m valid_report\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvalidation loss\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    533\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\2023Spring\\envtext\\src\\envtext\\models\\model_base.py:799\u001b[0m, in \u001b[0;36mModelBase._report\u001b[1;34m(self, dic)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnotebook_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m in_notebook\n\u001b[0;32m    798\u001b[0m \u001b[39mif\u001b[39;00m in_notebook():\n\u001b[1;32m--> 799\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ipython_report(dic)\n\u001b[0;32m    800\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_report(dic)\n",
      "File \u001b[1;32md:\\2023Spring\\envtext\\src\\envtext\\models\\model_base.py:790\u001b[0m, in \u001b[0;36mModelBase._ipython_report\u001b[1;34m(self, dic)\u001b[0m\n\u001b[0;32m    788\u001b[0m     markdown \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    789\u001b[0m     \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m dic\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 790\u001b[0m         markdown \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39;49m\u001b[39m{:.4f}\u001b[39;49;00m\u001b[39m|\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(v)\n\u001b[0;32m    791\u001b[0m     markdown \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m  \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    793\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display_markdown\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to list.__format__"
     ]
    }
   ],
   "source": [
    "model.train(epoch=8,batch_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
